{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MF5gqlesfXLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323ad266-abf5-4ec1-ee5d-c5ac19c6c782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-8b863c13f0ab>:26: DeprecationWarning: Please use `convolve` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
            "  from scipy.ndimage.filters import convolve\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import os.path\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, LeakyReLU, Reshape, ReLU\n",
        "from tensorflow.keras.layers import Conv2DTranspose, Conv2D, Dropout, Flatten,Input\n",
        "import time\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.datasets.fashion_mnist import load_data\n",
        "from IPython import display\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import imageio\n",
        "import PIL, cv2\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "from skimage.morphology import convex_hull_image, erosion\n",
        "from skimage.morphology import square\n",
        "import matplotlib.image as mpimg\n",
        "import skimage\n",
        "import math\n",
        "from scipy.ndimage.filters import convolve\n",
        "from PIL import Image,ImageFilter\n",
        "from skimage.feature import hessian_matrix, hessian_matrix_eigvals"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generated Dataset"
      ],
      "metadata": {
        "id": "jDH92aaqbYw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the folder to save the images\n",
        "\n",
        "'''\n",
        "folder_path = '/content/generated_fingerprints'\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "for i in range(6000):\n",
        "    # Add some random noise to the input noise vector\n",
        "    noise = tf.random.normal([1, noise_dim])\n",
        "    \n",
        "    # Generate a synthetic fingerprint using the generator function\n",
        "    fingerprint = generator(noise, training=False)\n",
        "    \n",
        "    # Convert the TensorFlow tensor to a NumPy array\n",
        "    fingerprint_np = fingerprint.numpy()\n",
        "    \n",
        "    # Convert the fingerprint array to a PIL Image object\n",
        "    image = Image.fromarray((fingerprint_np[0] * 255).astype(np.uint8))\n",
        "    \n",
        "    # Save the image as a JPEG file in the folder\n",
        "    filename = f'generated_fingerprint_{i}.jpg'\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    image.save(file_path, 'JPEG')\n",
        "'''"
      ],
      "metadata": {
        "id": "T6pVDLmeFZhh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ab7c849c-3256-4e23-c778-58cc2574ab15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfolder_path = '/content/generated_fingerprints'\\nif not os.path.exists(folder_path):\\n    os.makedirs(folder_path)\\n\\nfor i in range(6000):\\n    # Add some random noise to the input noise vector\\n    noise = tf.random.normal([1, noise_dim])\\n    \\n    # Generate a synthetic fingerprint using the generator function\\n    fingerprint = generator(noise, training=False)\\n    \\n    # Convert the TensorFlow tensor to a NumPy array\\n    fingerprint_np = fingerprint.numpy()\\n    \\n    # Convert the fingerprint array to a PIL Image object\\n    image = Image.fromarray((fingerprint_np[0] * 255).astype(np.uint8))\\n    \\n    # Save the image as a JPEG file in the folder\\n    filename = f'generated_fingerprint_{i}.jpg'\\n    file_path = os.path.join(folder_path, filename)\\n    image.save(file_path, 'JPEG')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4Hlk5R6GZ_x",
        "outputId": "caf4840f-c0be-4082-8d85-7cc8d6954142"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "#folder_path = '/content/generated_fingerprints'\n",
        "#drive_path = '/content/gdrive/MyDrive/generated_fingerprints'\n",
        "#os.makedirs(drive_path, exist_ok=True)\n",
        "#for file_name in os.listdir(folder_path):\n",
        "#    shutil.copy(os.path.join(folder_path, file_name), os.path.join(drive_path, file_name))\n",
        "\n",
        "orig_folder = '/content/socofing/SOCOFing/Real'\n",
        "gen_folder = '/content/generated_fingerprints'"
      ],
      "metadata": {
        "id": "m94ZOMsjHW1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\n",
        "\n",
        "# Define paths to original and generated image folders\n",
        "orig_folder = '/content/gdrive/MyDrive/Socofing_png'\n",
        "gen_folder = '/content/gdrive/MyDrive/generated_fingerprints'\n",
        "\n",
        "# Initialize VGG16 model and get reference to the last convolutional layer\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False)\n",
        "last_layer = vgg_model.get_layer('block5_conv3')\n",
        "\n",
        "# Create a new model that outputs the last convolutional layer's feature map\n",
        "feature_extractor = tf.keras.models.Model(inputs=vgg_model.input, outputs=last_layer.output)\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def preprocess(img_path):\n",
        "    img = Image.open(img_path)\n",
        "    img = img.convert('RGB')  # convert to RGB format if necessary\n",
        "    img = img.resize((224, 224))  # resize the image\n",
        "    x = np.asarray(img)  # convert to numpy array\n",
        "    x = np.expand_dims(x, axis=0)  # add batch dimension\n",
        "    x = preprocess_input(x)  # preprocess using VGG16 preprocessing\n",
        "    return x\n",
        "\n",
        "# Extract features for original images\n",
        "orig_features = []\n",
        "for filename in os.listdir(orig_folder):\n",
        "    if filename.endswith('.png'):\n",
        "        img_path = os.path.join(orig_folder, filename)\n",
        "        x = preprocess(img_path)\n",
        "        features = feature_extractor.predict(x)\n",
        "        features = np.reshape(features, (features.shape[0], -1))\n",
        "        orig_features.append(features)\n",
        "\n",
        "# Extract features for generated images\n",
        "gen_features = []\n",
        "for filename in os.listdir(gen_folder):\n",
        "    if filename.endswith('.jpg'):\n",
        "        img_path = os.path.join(gen_folder, filename)\n",
        "        x = preprocess(img_path)\n",
        "        features = feature_extractor.predict(x)\n",
        "        features = np.reshape(features, (features.shape[0], -1))\n",
        "        gen_features.append(features)"
      ],
      "metadata": {
        "id": "Ns0vPJuwKtE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "orig_features = np.concatenate(orig_features, axis=0)\n",
        "gen_features = np.concatenate(gen_features, axis=0)\n",
        "\n",
        "# Concatenate original and generated feature vectors into a single array\n",
        "all_features = np.concatenate([orig_features, gen_features], axis=0)\n",
        "\n",
        "# Fit a KNN model on the original feature vectors\n",
        "n_neighbors = 5  # Choose the number of neighbors for the KNN model\n",
        "knn_model = NearestNeighbors(n_neighbors=n_neighbors, metric='euclidean')\n",
        "knn_model.fit(orig_features)\n",
        "\n",
        "# Compute the average distance from each generated feature vector to its nearest neighbor in the original dataset\n",
        "distances, _ = knn_model.kneighbors(gen_features)\n",
        "avg_dist = np.mean(distances)\n",
        "\n",
        "print(\"KNN score: \", avg_dist)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AimI2TMiMBUX",
        "outputId": "20d8279f-a115-4a65-a0d7-1c9ff6ee1d48"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN score:  1479.2690989948542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quando avevo fatto tutte e 6000 le immagine (BMP) lo score era circa a 1555. Con le prime 600 convertite (png) fa 1479 (e ci mette 18 minuti)."
      ],
      "metadata": {
        "id": "ceHJqlD76aH2"
      }
    }
  ]
}